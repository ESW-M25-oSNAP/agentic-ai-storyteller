Project

We are working on a project wherein we’re trying to implement resource sharing for running AI models on edge devices.
We need your help in writing code to do the same. In detail, we will explain the workflows with checkpoints. You must step by step implement the code until each checkpoint. I will then verify whether or not that’s working. If it is working, we’ll move onto the next checkpoint. Otherwise, we stop.


Overall Summary

Here's what we want to do:
 
INITIAL PHASE: Orchestrator on Laptop
 
A single orchestrator runs on the laptop and establishes a connection once between the laptop and at least 2 (or n) android devices. When an android device captures an image it sends it first to the orchestrator. The orchestrator details its requirements to each device and then each device bids its availability to the orchestrator. The orchestrator then assigns the task (image classification followed by text generation) to one of the devices based on a "bidding algorithm." We would have to try to develop this bidding algorithm as well, to ensure its optimality in choosing a target device.
 
This is proof of concept for sharing resources for running SLMs across edge devices.
 
 
 
EXTENSION: Orchestrator on (1 or all) Android Device(s)
 
Now, in this part, instead of having the orchestrator running on the laptop, we have the orchestrator running an android device. We will call the Android device on which this model is running X. X is connected to every other Android device. When it captures an image, all devices (including X itself) send their bid to run the orchestrator. The winner is selected based on the bidding algorithm and the image is sent for classification to the model with the winning bid. 
 
Now to further this, if we were able to connect all devices in the network P2P and have the orchestrator running on each device (independently, no 2 orchestrators communicate with each other), we could develop a system in which each device can utilize the resources of the other devices whenever required, to gain an optimal output by complete resource sharing.



What this means in terms of code

Ok, so now I’m going to break this up into a few key check-points. Do not worry at all about the extension, for now we’re just working on the initial phase. Also note that for testing purposes we will be running Inception-V3, which is already setup on the Android devices.

STEP 1 - Setup

A picture will be taken on one of the android devices. This picture will be stored in `/storage/emulated/0/Pictures`. We want to move this from here to the laptop (orchestrator).
The laptop then requests both (or all) devices on the network to send a bid for the picture to be run on a model on their device. 

Note that here laptop and orchestrator are being used as interchangeable terms.
Checkpoint 1 - Picture sent to laptop, laptop requests bids, bids received by laptop.


STEP 2 - Evaluation of Bids

For now, we do not have a bidding algorithm in place, just assume this bidding algorithm to be “whoever has the lowest CPU load, runs the model on that device.” 
Send the picture back to the device with the lowest CPU load. Send it to `/data/local/tmp/received-image`
Checkpoint 2 - Everything up to here should be working. I will tell you if the image has been received in `/data/local/tmp/received-image`


STEP 3 - Running the Model and returning the output

Now, the device that has received the image from the orchestrator after being chosen, runs Inception-V3. It then returns the identified object (s) to the orchestrator. 

Checkpoint 3 - Model running, and output received by the laptop.

STEP 4 - Continuing the pipeline

For the next part of the pipeline, the orchestrator then uses a similar bidding process - deciding based on cpu load - to decide the device on which to run the t2t. It chooses the device and sends the text message to that device. 

STEP 5 - Returning final result

The chosen device then runs the t2t model and sends the final result (story) back to the orchestrator. The user then observes the final output on the laptop and the pipeline is completed. 
